# llama-llm-inference-base-container
This docker container contains the base dependecies of llama.cpp to run any huggingface GGUF models
